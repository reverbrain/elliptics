###################################
# elliptics-core

## log file
# set to 'syslog' without inverted commas if you want elliptics to log through syslog
# if you want write log to the file, create appropriate directory first
log = /dev/stderr

## log level. It doesn't corresponds to syslog levels. When logging to syslog
# almost all messages will be written with INFO level.
# DNET_LOG_DATA		= 0
# DNET_LOG_ERROR	= 1
# DNET_LOG_INFO		= 2
# DNET_LOG_NOTICE	= 3
# DNET_LOG_DEBUG	= 4
log_level = 3

## specifies whether to join storage network. Server nodes should use 1,
# client nodes don't use this parameter or set it to 0.
join = 1

## config flags
# bits start from 0, 0 is unused (its actuall above join flag)
# bit 1 (flags=1) - do not request remote route table
# bit 2 (flags=4) - mix states before read operations according to state's weights
# bit 3 (flags=8) - do not checksum data on upload and check it during data read
# bit 4 (flags=16) - do not update metadata at all
# bit 5 (flags=32) - randomize states for read requests
# bit 6 (flags=64) - keeps ids in elliptics cluster
# bits can be set in any variations, but in case of bits 2 and 5 set both, 2 will be used.
flags = 4

## node will join nodes in this group
# Group is a synonim for replica or copy. If multiple servers with the same group ID
# join elliptics network, group will contain multiple nodes and load will be spread
# to those servers. If multiple servers with different group IDs join elliptics network,
# there will be multiple groups and thus client will be able to write multiple copies.
group = 2

## list of remote nodes to connect
#
# `address:port:family` where family is either 2 (AF_INET) or 10 (AF_INET6)
# address can be host name or IP
#
# Multicast doesn't used this time.
# It is possible to autodiscover remote clusters via multicast.
# If you put `autodiscovery:address:port:family` where `address:port:family` is valid multicast address,
# elliptics will broadcast information about itself and remote nodes with the same auth cookie will
# receive this information and connect to given node. Multicast TTL equals to 3.
#
remote = 1.2.3.4:1025:2 2.3.4.5:2345:2 autodiscovery:224.0.0.5:1025:2

## multiple interface support
# Elliptics server listens on port specified in this config option (format: addr:port:family-route_group)
# If ports differ, the last one will be used.
#
# Elliptics server will accept connections from any address, but it has to understand which addresses of
# the other connected joined servers it has to send to newly accepted client. Thus we 'join' multiple
# addresses on every node into 'logical route tables' which are indexed by the last number in addr
# config option. Thus, format becomes: local_address:port:family-route_group
#
# Addresses in the same route group on different servers will be put into the same route tables,
# thus when client in example below connects to localhost, it will receive (and connect to) addresses
# from the logical route group 0 (whatever addresses will be put into that route group on other servers).
#
# Let's suppose we have 3 connected servers with the following addresses
# srv0: 10.0.0.17:1025:2-0 192.168.0.17:1025:2-1 20.20.20.17:1025:2-2
# srv1: 10.0.0.34:1025:2-0 192.168.0.34:1025:2-1 20.20.20.34:1025:2-2
# srv2: 15.14.13.12:1025:2-0 99.99.99.99:1025:2-1 111.111.111.111:1025:2-2
#
# When client connects to srv1 to IP address 192.168.0.34:1025, it will receive (and connect to)
# following route table:
# 192.168.0.17:1025 192.168.0.34:1025 99.99.99.99:1025
#
# Because above addresses are in the same logical route group and client
# connected to one of the addresses in that logical route group.
#
# `addr` is a list of interfaces that server binds
addr = localhost:1025:2-0 10.10.0.1:1025:2-1

## wait timeout specifies number of seconds to wait for command completion
wait_timeout = 60

## this timeout specifies number of seconds to wait before killing
# unacked transaction. This parameter is used also for some service operations such as
# update the routing server, check network connections an so on.
check_timeout = 60

## number of IO threads in processing pool. Typically, value of this parameter should be comparable
# with the number of hardware processing cores.
io_thread_num = 16

## number of IO threads in processing pool dedicated to nonblocking operations
# they are invoked from recursive commands like DNET_CMD_EXEC, when script
# tries to read/write some data using the same id/key as in original exec command
# Typically, value of this parameter should be comparable with the number of hardware processing cores.
nonblocking_io_thread_num = 16

## number of threads in network processing pool
net_thread_num = 16

## specifies history environment directory
# it will host file with generated IDs
# and server-side execution scripts
# should be created manually before use
history = /tmp/history

## specifies whether to go into background
daemon = 0

## authentication cookie
# this cookie is not meant for real authentification, it is transferred in plain text without encryption
# instead it is used to check server configurations - servers with different cookies can not connect
# to each other, and thus node can not join cluster with different cookie
#
# client can connect to any cluster no matter what cookie is used
#
# auth_cookies is a byte array with 32-byte length
auth_cookie = qwerty

## Background jobs (replica checks and recovery) IO priorities
# ionice for background operations (disk scheduler should support it)
# class - number from 0 to 3
# 0 - default class
# 1 - realtime class
# 2 - best-effort class
# 3 - idle class
bg_ionice_class = 3
# prio - number from 0 to 7, sets priority inside class
bg_ionice_prio = 0

## IP priorities
# man 7 socket for IP_PRIORITY
# server_net_prio is set for all joined (server) connections
# client_net_prio is set for other connection
# is only turned on when non zero
server_net_prio = 1
client_net_prio = 6

## In-memory cache support
# This is maximum cache size. Cache is managed by LRU algorithm
# Using different IO flags in read/write/remove commands one can use it
# as cache for data, stored on disk (in configured backend),
# or as plain distributed in-memory cache
cache_size = 102400

## Index shard count
# Every index is being split to this number of 'shards'
# Shards are likely to be spread over your cluster evenly, but if number of servers is less
# than number of shards, this will slow the whole index operations noticebly.
# For example, if you have 1 node and 10 shards, index 'find' will be 10 times slower than 1-shard-setup
# Otherwise, if number of servers is high enough, the more shards you have more parallel is index processing.
#
# Operations like 'update' (put key into index) or 'set' (put key into index if key is not present already)
# does not depend on number of shards, this is single read+read+write operation anyway (at worst).
indexes_shard_count = 2

## Monitor port
# If monitor port is specified then elliptics listens the port
# and provides monitor data for each connections.
monitor_port = 20000

###################################
#SRW - server-side scripting

## srw worker config
# Elliptics uses cocaine engine (https://github.com/organizations/cocaine) for its server-side workers
# srw_config should point to its configuration file, example config lives in tree in example/library_config.json file
# If you use this parameter, cocaine should be installed and configured with a confidence, or elliptics will not start.
# srw_config = /opt/elliptics/library_config.json

###################################
# backend
# anything below this line will be processed
# by backend's parser and will not be able to
# change global configuration
# backend can be 'filesystem' or 'blob'

backend = filesystem

## Number of bits (from the beginning of the object ID) used
# for directory, which hosts given object
directory_bit_number = 8

## Root directory for data objects. Should be created manually before use.
root = /tmp/root

## zero here means 'sync on every write'
# positive number means file writes are never synced
# and metadata is synced every `sync` seconds
sync = 0


#backend = blob

## zero here means 'sync on every write'
# positive number means data and metadata updates
# are synced every `sync` seconds
#sync = 0

## eblob objects prefix. System will append .NNN and .NNN.index to new blobs. Path to blobs should be created manually before use.
# If prefix is `/tmp/blob/data`, path `/tmp/blob` should be created.
#data = /tmp/blob/data

## blob processing flags (bits start from 0)
# bit 0 - if set, eblob reserves 10% of total space or size of the blob (which is bigger)
# 		By default it is turned off and eblob only reserves size of the blob
# 		This is useful (required) to be able to run defragmentation
# bit 1 - deprecated overwrite commits mode. Starting from eblob 0.20.0 it's default behaviour.
# bit 2 - deprecated overwrite mode. Starting from eblob 0.20.0 it's default behaviour.
# bit 3 - do not append checksum footer - this saves 72 bytes per written record.
# 		This also disables checksum.
# bit 4 - do not check whether system has enough space for the new blob
# bit 5 - reserved for internal use, do not set
# bit 6 - use second hashing layer - reduces memory usage for in-memory eblob index (costs some IOPS).
# bit 7 - auto data-sort. When set, eblob will perform data sorting as well as defragmentation and index sorting on startup and
#               on blob close. This is prefered "set and forget" behaviour for small databases.
# bit 8 - timed data-sort. When set eblob will run data-sort on every non-sorted blob each `defrag_timeout` seconds.
#		This is legacy behaviour for compatibility with old setups.
# bit 9 - scheduled data-sort. When set eblob will run data sort starting at `defrag_time` +/- `defrag_splay` hours.
#               Probably one hould set this values to match clusters "mostly-idle" hours.
#               This option was introduced to "spread" defragmentation load across nodes in cluster in time.
#               This is prefered "set and forget" behaviour for not-so-big clusters.
#
# For very big clusters it's recommended to disable all `auto-data-sort`
# features and manually run 'dnet_ioclient ... -d' command with external synchronization.
#
# Also data-sort will try to defragment even already sorted blobs if they've
# reached `defrag_percentage` fragmentation or they are way too small so there
# is good probability they will be merged into one.
#
#blob_flags = 1

## Number of threads used to populate data into RAM at startup.
# This greatly speeds up data-sort/defragmentation and somehow speeds up startup.
# Also this threads are used for iterating by start_iterator request.
# Default: 1
#iterate_thread_num = 4

## Maximum blob size. New file will be opened after current one
# grows beyond `blob_size` limit
# Supports K, M and G modifiers
#blob_size = 10G

## Maximum number of records in blob.
# When number of records reaches this level,
# blob is closed and sorted index is generated.
# Its meaning is similar to above `blob_size`,
# except that it operates on records and not bytes.
# Both parameters `blob_size` and `records_in_blob` can be used together or separately
#records_in_blob = 10000000

## Timeout for data-sort process to start
# Data-Sort/Defragmentation operation is rather costly (even if nothing is
# going to be copied, defragmentation still checks every index to determine
# number of removed keys)
# It is recommended to set it to hours (it is in seconds) or more>
# NB! Only works if bit 8 of config flags is set.
# Default: -1 or none
#defrag_timeout = 3600

## Percentage of removed entries (compared to number of all keys in blob)
# needed to start defragmentation. If blob is already sorted and number of
# removed keys is less than (removed + not removed) * $defrag_percentage / 100
# then defragmentation process will skip given blob
#defrag_percentage = 25

## Scheduled defragmentation start time and splay.
# Both time and splay are specified in hours in local timezone, so that on big
# clusters defragmentation load could be spread in time at "mostly-idle" hours.
# NB! Only works if bit 9 of config flags is set.
#defrag_time = 3
#defrag_splay = 3

## Maximum size whole eblob can occupy on disk
# Basically, this is the maximum size eblob data directory can occupy on disk
#blob_size_limit = 10G

## Bloom filter parameters
# index_block_size - number of records from index file, which are hashed into one bloom filter
# eblob splits all records from sorted index file into chunks, each chunk has start and finish
# keys only and bloom filter which says whether requested entry can be found in given chunk
# index_block_bloom_length - number of bits per chunk, it should be at least as twice as number
# of records in chunk
#
# Default values:
# index_block_size = 40
# index_block_bloom_length = 128 * 40
